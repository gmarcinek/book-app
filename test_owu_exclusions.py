#!/usr/bin/env python3
"""
Simple test: Find EXCLUSIONS from OWU document using GPT-4.1-nano
Tests if LLM can identify WYÅÄ„CZENIE_Z_UMOWY entities from the document
"""

import sys
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from llm import LLMClient, LLMConfig, Models
from ner.domains.owu.owu_consts import format_owu_entity_types

def load_owu_document(file_path: str) -> str:
    """Load OWU markdown document"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        print(f"ğŸ“„ Loaded document: {len(content):,} characters")
        return content
    except Exception as e:
        print(f"âŒ Failed to load document: {e}")
        return ""

def test_find_exclusions(document_text: str) -> dict:
    """Test LLM ability to find exclusions from OWU document"""
    
    # Simple, clear NER prompt
    prompt = f"""JesteÅ› systemem NER (Named Entity Recognition) ktÃ³ry wyciÄ…ga encje z dokumentÃ³w ubezpieczeniowych.

Twoje zadanie: znajdÅº wszystkie sytuacje kiedy ubezpieczyciel NIE wypÅ‚aci odszkodowania lub co NIE jest objÄ™te ubezpieczeniem.

TEKST DOKUMENTU:
{document_text}

SZUKAJ ODPOWIEDZI NA PYTANIA:
- Co NIE jest objÄ™te ubezpieczeniem?
- Kiedy ubezpieczyciel NIE wypÅ‚aci odszkodowania?
- Jakie sÄ… ograniczenia i wyÅ‚Ä…czenia?
- W jakich sytuacjach odmÃ³wiÄ… wypÅ‚aty?

WZORCE DO SZUKANIA:
- "nie obejmuje", "wyÅ‚Ä…cza siÄ™", "nie podlega"
- "odmowa wypÅ‚aty", "nie wypÅ‚aca siÄ™"
- "ograniczenia odpowiedzialnoÅ›ci"
- Listy wyÅ‚Ä…czeÅ„: a), b), c) lub 1., 2., 3.

INSTRUKCJE:
1. KaÅ¼dy punkt wyÅ‚Ä…czenia = osobna encja
2. Zapisz dokÅ‚adnie w ktÃ³rym artykule/punkcie znalazÅ‚eÅ›
3. Nadaj prostÄ…, opisowÄ… nazwÄ™
4. Skopiuj kluczowy fragment jako dowÃ³d

JSON (max 10 najwaÅ¼niejszych wyÅ‚Ä…czeÅ„):
{{
  "entities": [
    {{
      "type": "EXCLUSION",
      "name": "deskryptywna_nazwa_podstawowa",
      "description": "semantycznie uÅ¼yteczny opis dla wyszukiwarki embedera, minimalna dÅ‚ugoÅ›Ä‡ to 10 sÅ‚Ã³w, sprÃ³buj powiedzieÄ‡ i ekstrapolowaÄ‡ jak najwiecej moÅ¼na prawdziwych stwierdzeÅ„ na temat encji",
      "confidence": 0.9,
      "evidence": "art X, pkt Y",
      "aliases": ["choroby wczeÅ›niejsze", "schorzenia uprzednie"]
    }}
  ]
}}

ZwrÃ³Ä‡ TYLKO JSON bez komentarzy."""

    # Initialize LLM client
    print(f"ğŸ¤– Using model: {Models.GPT_4_1_MINI}")
    llm_client = LLMClient(Models.GPT_4_1_MINI)
    config = LLMConfig(temperature=0.0, max_tokens=24000)
    
    try:
        print("ğŸ” Sending request to LLM...")
        response = llm_client.chat(prompt, config)
        print(f"âœ… Got response: {len(response)} characters")
        return {
            "status": "success",
            "response": response,
            "prompt_length": len(prompt),
            "response_length": len(response)
        }
    except Exception as e:
        print(f"âŒ LLM request failed: {e}")
        return {
            "status": "error",
            "error": str(e)
        }

def parse_and_display_results(response_data: dict):
    """Parse LLM response and display results"""
    if response_data["status"] != "success":
        print(f"âŒ Test failed: {response_data['error']}")
        return
    
    response = response_data["response"]
    
    # Try to parse JSON
    try:
        import json
        
        # Clean response
        clean_response = response.strip()
        if '```json' in clean_response:
            clean_response = clean_response.split('```json')[1].split('```')[0]
        elif '```' in clean_response:
            parts = clean_response.split('```')
            if len(parts) >= 3:
                clean_response = parts[1]
        
        data = json.loads(clean_response.strip())
        entities = data.get('entities', [])
        
        print(f"\nğŸ¯ RESULTS: Found {len(entities)} exclusions")
        print("=" * 80)
        
        for i, entity in enumerate(entities, 1):
            name = entity.get('name', 'Unknown')
            description = entity.get('description', '')
            confidence = entity.get('confidence', 0.0)
            evidence = entity.get('evidence', '')
            
            print(f"\n{i}. {name}")
            print(f"   ğŸ“ Description: {description}")
            print(f"   ğŸ“Š Confidence: {confidence}")
            print(f"   ğŸ” Evidence: {evidence[:100]}...")
        
        print("=" * 80)
        print(f"ğŸ“Š Stats: {response_data['prompt_length']:,} chars prompt â†’ {response_data['response_length']:,} chars response")
        
    except json.JSONDecodeError as e:
        print(f"âŒ Failed to parse JSON response: {e}")
        print(f"Raw response: {response[:500]}...")
    except Exception as e:
        print(f"âŒ Error processing results: {e}")

def main():
    """Main test function"""
    import argparse
    
    parser = argparse.ArgumentParser(description="OWU Exclusions Test - GPT-4.1-nano")
    parser.add_argument("file_path", help="Path to OWU document (e.g., docs/owu_COMBINED_5281a67c.md)")
    args = parser.parse_args()
    
    print("ğŸ§ª OWU Exclusions Test - GPT-4.1-nano")
    print("=" * 50)
    
    # Load document from provided path
    document_text = load_owu_document(args.file_path)
    
    if not document_text:
        print("âŒ No document loaded, exiting")
        return
    
    # Test finding exclusions
    print("\nğŸ” Testing exclusion detection...")
    results = test_find_exclusions(document_text)
    
    # Display results
    print("\nğŸ“‹ Processing results...")
    parse_and_display_results(results)

if __name__ == "__main__":
    main()