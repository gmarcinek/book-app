# Luigi Pipeline Configuration
# Simple YAML config for all preprocessing tasks

# LLM Markdown Processor settings
LLMMarkdownProcessor:
  model: "gpt-4o-mini"
  temperature: 0.0
  # max_tokens: auto-calculated from llm.models

# PDF Processing settings
PDFProcessing:
  extract_images: true
  extract_tables: true

# Markdown Combiner settings
MarkdownCombiner:
  save_individual_pages: true
  save_combined_file: true
  output_dir: "output"

# File Router settings
FileRouter:
  supported_pdf_extensions: [".pdf"]
  supported_text_extensions: [".txt", ".md"]

# Provider-specific delays
provider_delays:
  ollama: 3.0
  openai: 0.0
  anthropic: 0.5

# Performance settings
performance:
  processing_timeout: 600 # seconds
  retry_attempts: 3
