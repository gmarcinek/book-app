# PLIK: luigi_pipeline/config.yaml

LLMMarkdownProcessor:
  model: "claude-4-sonnet"
  max_concurrent: 2 # NEW: sliding window size
  rate_limit_backoff: 30.0
  retry_failed_pages: true

AIHeaderDetector:
  model: "gpt-4.1-mini"
  temperature: 0.0

PDFProcessing:
  extract_images: true
  extract_tables: true

MarkdownCombiner:
  save_individual_pages: true
  save_combined_file: true
  output_dir: "output"

FileRouter:
  supported_pdf_extensions: [".pdf"]
  supported_text_extensions: [".txt", ".md"]

provider_delays:
  ollama: 3.0
  openai: 0.0
  anthropic: 0.5

performance:
  processing_timeout: 600
  retry_attempts: 3
