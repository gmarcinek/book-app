# Luigi TOC Pipeline - Dokumentacja Flow

## PrzeglÄ…d

Pipeline `luigi_toc_pipeline` sÅ‚uÅ¼y do automatycznej detekcji i ekstrakcji spisu treÅ›ci (Table of Contents) z dokumentÃ³w PDF. Pipeline wykorzystuje podejÅ›cie hybrydowe Å‚Ä…czÄ…ce heurystyki wzorcowe z weryfikacjÄ… LLM.

## Architektura Pipeline'u

Pipeline skÅ‚ada siÄ™ z 4 gÅ‚Ã³wnych moduÅ‚Ã³w Luigi poÅ‚Ä…czonych w Å‚aÅ„cuch zaleÅ¼noÅ›ci:

```
run_toc_pipeline.py
    â†“
TOCOrchestrator
    â†“
TOCFallbackLLMStrategy
    â†“
TOCHeuristicDetector
    â†“
    â”œâ”€â”€ TOCPatternDetector (Stage 1)
    â””â”€â”€ TOCVerificationEngine (Stage 2)
```

---

## ModuÅ‚ 1: `run_toc_pipeline.py` - Punkt WejÅ›cia

**Lokalizacja:** `luigi_toc_pipeline/run_toc_pipeline.py`

### Zadanie
Inicjalizuje pipeline Luigi dla pojedynczego pliku PDF.

### Proces
1. Waliduje argument wiersza poleceÅ„ (Å›cieÅ¼ka do PDF)
2. Sprawdza czy plik istnieje
3. Uruchamia Luigi scheduler z taskiem `TOCOrchestrator`

### UÅ¼ycie
```bash
python run_toc_pipeline.py <pdf_file>
```

### WyjÅ›cie
- âœ… Sukces: "Pipeline completed successfully" (exit code 0)
- âŒ BÅ‚Ä…d: "Pipeline failed" (exit code 1)

---

## ModuÅ‚ 2: `TOCOrchestrator` - Orkiestrator GÅ‚Ã³wny

**Lokalizacja:** `luigi_toc_pipeline/tasks/toc_orchestrator.py`

### Zadanie
Agreguje wyniki z wczeÅ›niejszych etapÃ³w i tworzy finalne podsumowanie procesu detekcji TOC.

### Proces
1. Odbiera wyniki z `TOCFallbackLLMStrategy`
2. JeÅ›li TOC znaleziony (`toc_found: true`):
   - Ekstrahuje strukturalne dane TOC
   - Wydobywa wspÃ³Å‚rzÄ™dne (start_page, end_page, start_y, end_y)
   - Przygotowuje listÄ™ entries z licznikami
3. JeÅ›li TOC nie znaleziony:
   - Tworzy raport negatywny z powodem

### WyjÅ›cie JSON

**Sukces (TOC znaleziony):**
```json
{
  "task_name": "TOCOrchestrator",
  "input_file": "/path/to/file.pdf",
  "toc_found": true,
  "detection_method": "llm_processing_merged",
  "coordinates": {
    "start_page": 2,
    "end_page": 4,
    "start_y": 150.5,
    "end_y": 780.2
  },
  "toc_entries": [...],
  "toc_entries_count": 25,
  "ready_for_splitting": true,
  "processing_stats": {
    "certain_count": 1,
    "uncertain_count": 0,
    "processed_count": 1,
    "rejected_count": 3
  }
}
```

**Niepowodzenie (brak TOC):**
```json
{
  "task_name": "TOCOrchestrator",
  "input_file": "/path/to/file.pdf",
  "toc_found": false,
  "reason": "no_confirmed_tocs_after_processing",
  "ready_for_splitting": false,
  "processing_stats": {...}
}
```

### Logi konsoli
```
âœ… TOC orchestration complete: 25 entries found
   Method: llm_processing_merged
   Coverage: pages 2-4
```

---

## ModuÅ‚ 3: `TOCFallbackLLMStrategy` - Strategia Fallback

**Lokalizacja:** `luigi_toc_pipeline/tasks/toc_fallback_llm_strategy/toc_fallback_llm_strategy.py`

### Zadanie
Warstwa strategii fallback - w przyszÅ‚oÅ›ci ma implementowaÄ‡ Å‚aÅ„cuch:
1. Built-in TOC (PDF metadata)
2. Heuristic detection (obecne)
3. Semantic fallback (TODO)

### Obecna Implementacja
**Preleotka (pass-through)** - przekazuje wynik z `TOCHeuristicDetector` bez zmian.

### Planowane rozszerzenia (TODO)
```python
# Planowany flow:
1. doc.get_toc() â†’ jeÅ›li found, return
2. TOCHeuristicDetector â†’ jeÅ›li found, return
3. Semantic LLM fallback â†’ jeÅ›li found, return
4. Return toc_found: false
```

### WyjÅ›cie
Przekazuje niezmieniony JSON z `TOCHeuristicDetector`, dodaje pole `method`.

---

## ModuÅ‚ 4: `TOCHeuristicDetector` - GÅ‚Ã³wny Silnik Detekcji

**Lokalizacja:** `luigi_toc_pipeline/tasks/toc_heuristic_detector/toc_heuristic_detector.py`

### Zadanie
Dwuetapowa detekcja TOC:
- **Stage 1:** Heurystyczna detekcja wzorcÃ³w (TOCPatternDetector)
- **Stage 2:** Weryfikacja LLM (TOCVerificationEngine)

### Proces

#### Krok 1: Inicjalizacja
```python
config = load_config()  # Wczytuje config.yaml
doc = fitz.open(self.file_path)  # PyMuPDF
max_pages = min(config.max_pages_to_scan, len(doc))  # DomyÅ›lnie: 1000
```

#### Krok 2: Stage 1 - Pattern Detection
```python
pattern_detector = TOCPatternDetector(doc, max_pages, config)
toc_candidates = pattern_detector.find_all_toc_candidates()
```

**Wynik:** SÅ‚ownik z 3 kategoriami:
```python
{
  'certain': [...],      # Pewne TOC (high confidence)
  'uncertain': [...],    # Niepewne (do weryfikacji LLM)
  'rejected': [...]      # Odrzucone false positives
}
```

**Logi:**
```
ğŸ” Found 1 certain TOCs
ğŸ” Found 2 uncertain TOCs
ğŸ” Rejected 3 false positives
```

#### Krok 3: Debug Export
```python
debug_utils.save_detection_summary(toc_candidates, self.file_path)
```
Zapisuje debug PDFs do `output/{document_name}/debug/`.

#### Krok 4: Stage 2 - LLM Processing
```python
all_candidates = certain + uncertain
verification_engine = TOCVerificationEngine(pdf_path, config)
processed_tocs = verification_engine.process_all_candidates(all_candidates)
```

**Warunki przerwania:**
- Zbyt wiele kandydatÃ³w: `len(all_candidates) > 25`
- Zbyt wiele odrzuceÅ„ LLM: `rejected_count >= 4`
- Zbyt wiele bÅ‚Ä™dÃ³w LLM: `failure_count >= 3`

**Logi:**
```
ğŸ¤– Starting LLM processing for 3 TOC candidates...
   âœ… Processed TOC at page 2
   âŒ Rejected TOC at page 15
ğŸ¯ Processed 1/3 TOCs
```

#### Krok 5: Merging Multiple TOCs
```python
final_result = self._merge_all_tocs(processed_tocs)
```

**Co robi:**
- ÅÄ…czy entries z wszystkich potwierdzonych TOC
- Usuwa duplikaty (po title + page)
- Sortuje po numerze strony
- Oblicza globalne wspÃ³Å‚rzÄ™dne (min start_page â†’ max end_page)

**Logi:**
```
ğŸ”— Merging 2 TOC sections...
   TOC at page 2: 15 entries
   TOC at page 5: 12 entries
ğŸ“‹ Merged result: 25 unique entries
   Coverage: pages 2-5
```

### WyjÅ›cie JSON

**Sukces:**
```json
{
  "status": "success",
  "toc_found": true,
  "start_page": 2,
  "start_y": 150.5,
  "end_page": 5,
  "end_y": 780.2,
  "confidence": "high",
  "detection_method": "llm_processing_merged",
  "entry_count": 25,
  "toc_entries": [...],
  "merged_sections": 2,
  "certain_count": 1,
  "uncertain_count": 2,
  "processed_count": 2,
  "rejected_count": 1
}
```

**Niepowodzenie:**
```json
{
  "status": "success",
  "toc_found": false,
  "reason": "no_confirmed_tocs_after_processing",
  "certain_count": 0,
  "uncertain_count": 0,
  "processed_count": 0,
  "rejected_count": 5
}
```

---

## Stage 1: `TOCPatternDetector` - Detekcja WzorcÃ³w

**Lokalizacja:** `luigi_toc_pipeline/tasks/toc_heuristic_detector/pattern_detector.py`

### Zadanie
ZnajdÅº wszystkie potencjalne TOC uÅ¼ywajÄ…c heurystyk wzorcowych i kategoryzuj wedÅ‚ug pewnoÅ›ci.

### Proces

#### Krok 1: ZnajdÅº TOC Start
```python
for page_num in range(max_pages):
    toc_start = _find_toc_start_on_page(page_num)
```

**Wzorce TOC (z config.yaml):**
```yaml
toc_keywords:
  - "spis treÅ›ci"
  - "treÅ›Ä‡"
  - "table of contents"
  - "contents"
  - "indice"
  - "sommaire"
  - "chapter contents"
```

**Regex matching:**
```python
pattern = r'\b{keyword}\b'  # Word boundary matching
```

#### Krok 2: ZnajdÅº TOC End
```python
toc_end = _find_toc_end_from_start(toc_start)
```

**Strategia:**
- Skanuj do 3 stron od startu
- Liczy linie wyglÄ…dajÄ…ce jak TOC entries
- Liczy wszystkie linie (total_lines)
- Oblicza `toc_ratio = toc_entries / total_lines`

**Wzorce TOC Entry:**
```python
patterns = [
    r'.+\.{3,}\s*\d+\s*$',           # "Title....... 25"
    r'.+\s{3,}\d+\s*$',              # "Title    25"
    r'.+\t+\d+\s*$',                 # "Title\t\t25"
    r'^\d+\.?\d*\.?\s*.+\s+\d+\s*$', # "1.1 Title 25"
    r'^(chapter|rozdziaÅ‚).*\d+\s*$', # "Chapter 1 ... 25"
    r'.+\s*\(\d+\)\s*$',             # "Title (25)"
]
```

**Koniec TOC wykrywany przez:**
- Content start patterns (np. "RozdziaÅ‚ 1", "Introduction")
- Lub fallback: po 3 stronach lub po ostatnim entry

**Content Start Patterns:**
```python
patterns = [
    r'^(rozdziaÅ‚|rozdzial)\s+\d+',
    r'^(czÄ™Å›Ä‡|czesc)\s+\d+',
    r'^(wprowadzenie|wstÄ™p|wstep)',
    r'^(chapter|part)\s+\d+',
    r'^(introduction|preface)',
    # ... i wiÄ™cej
]
```

#### Krok 3: Kategoryzacja KandydatÃ³w
```python
return _categorize_candidates(all_candidates)
```

**Kryteria kategoryzacji:**

**CERTAIN (pewne):**
- `proximity_ok = True` (TOC blisko swojego content)
- `page_distance <= 1` (TOC na max 1 stronie)

**UNCERTAIN (niepewne):**
- `proximity_ok = True`
- `page_distance <= 5` (TOC do 5 stron)

**REJECTED (odrzucone):**
- `proximity_ok = False` OR `page_distance > 5`

**Logi kategoryzacji:**
```
ğŸ” Categorizing 5 candidates...
   Candidate 0: page 2, entries=15, total=18, ratio=0.83, proximity=True
     â†’ CERTAIN
   Candidate 1: page 15, entries=5, total=20, ratio=0.25, proximity=True
     â†’ UNCERTAIN
   Candidate 2: page 50, entries=2, total=10, ratio=0.20, proximity=False
     â†’ REJECTED: bad_proximity
```

### WyjÅ›cie
```python
{
  'certain': [
    {
      'start_page': 2,
      'start_y': 150.5,
      'end_page': 3,
      'end_y': 780.2,
      'entry_count': 15,
      'total_lines': 18,
      'toc_ratio': 0.83,
      'pattern_matched': r'\bspis treÅ›ci\b',
      'matched_text': 'spis treÅ›ci',
      'method': 'pattern',
      'candidate_id': 'toc_2_150'
    }
  ],
  'uncertain': [...],
  'rejected': [...]
}
```

---

## Stage 2: `TOCVerificationEngine` - Weryfikacja LLM

**Lokalizacja:** `luigi_toc_pipeline/tasks/toc_heuristic_detector/verification_engine.py`

### Zadanie
Weryfikuj kandydatÃ³w TOC uÅ¼ywajÄ…c LLM (GPT-4.1) do ekstrakcji strukturalnych danych.

### Proces

#### Krok 1: Walidacja liczby kandydatÃ³w
```python
if len(all_candidates) > 25:
    print("ğŸš¨ Too many candidates - aborting")
    return []
```

#### Krok 2: Przetwarzanie kaÅ¼dego kandydata
```python
for candidate in all_candidates:
    is_valid = _verify_single_candidate_with_processor(candidate)
```

**Dla kaÅ¼dego kandydata:**

##### 2a. UtwÃ³rz Temp PDF
```python
temp_pdf_path = _create_temp_toc_pdf(candidate)
```

**Cropping strategia:**
- GÃ³rny margines: `start_y - 100px` (100px przed TOC)
- Dolny margines: `start_y + 600px` (600px po TOC)
- PeÅ‚na szerokoÅ›Ä‡ strony
- PDF zapisywany do `output/{doc_name}/debug/toc_verification_{candidate_id}.pdf`

##### 2b. PDFLLMProcessor Config (z config.yaml)
```yaml
verification_processor:
  model: "gpt-4.1"
  clean_text: true
  temperature: 1.0
  reasoning_effort: "low"
  target_width_px: 700
  jpg_quality: 65
  max_concurrent: 1
  rate_limit_backoff: 30.0
```

##### 2c. Vision Prompt (uÅ¼ywany przez LLM)

**PeÅ‚ny prompt z config.yaml:**
```
Analyze the extracted Table of Contents (TOC) section using text and images.
EXTRACTED TEXT:
{text_content}

NOTE: This PDF contains only a fragment (middle or continuation) of the full TOC.
Page numbers refer to the original document.

TASK: Parse all visible TOC entries into a JSON object with a key "entries",
each entry having:

- "title": string â€” entry title
- "page": integer or null â€” original page number
- "level": integer â€” hierarchy level (1 = chapter, 2 = subsection, etc.)
- "type": string â€” one of "chapter", "section", or "article"

Example:

{
  "entries": [
    {"title": "RozdziaÅ‚ 1 - Wprowadzenie", "page": 15, "level": 1, "type": "chapter"},
    {"title": "1.1 Podstawowe pojÄ™cia", "page": 17, "level": 2, "type": "section"}
  ]
}

RULES:
- Include all visible entries, even if incomplete.
- Use images to verify text accuracy.
- Do not assume missing context; parse only visible data.
- Respond ONLY with valid JSON, no markdown, no explanations.
- Use standard ASCII double quotes and ESCAPE THEM PROPERLY.
- Escape all other special JSON characters as required.
```

##### 2d. Przetwarzanie odpowiedzi LLM
```python
processor = PDFLLMProcessor(processor_config, "TOCVerification")
results = processor.process_pdf(temp_pdf_path, parse_json_with_markdown_blocks)
```

**Filtrowanie entries:**
- âœ… Akceptuj: `entry.level is not None`
- âŒ OdrzuÄ‡: `entry.level is None` (brak hierarchii)

**Logi filtrowania:**
```
âš ï¸ Discarding entry 'Some Random Text' - no level detected
ğŸ“‹ Entry filtering: 15 valid, 2 discarded (NULL level)
ğŸ“‹ PDFLLMProcessor extracted 15 valid entries
```

##### 2e. Circuit Breakers (zabezpieczenia)

**Zbyt wiele odrzuceÅ„:**
```python
if rejected_count >= 4:
    print("ğŸš¨ Too many rejections - pattern detection likely failing")
    break
```

**Zbyt wiele bÅ‚Ä™dÃ³w:**
```python
if failure_count >= 3:
    print("ğŸš¨ Too many PDFLLMProcessor failures - aborting")
    break
```

#### Krok 3: Zapisz entries do candidate
```python
if all_entries:
    candidate['toc_entries'] = all_entries
    candidate['toc_entries_count'] = len(all_entries)
    candidate['confidence'] = 'llm_processed'
    candidate['method'] = 'llm_processing'
    processed_tocs.append(candidate)
```

### WyjÅ›cie

**Dla kaÅ¼dego przetworzonego TOC:**
```python
{
  'start_page': 2,
  'start_y': 150.5,
  'end_page': 3,
  'end_y': 780.2,
  'confidence': 'llm_processed',
  'method': 'llm_processing',
  'toc_entries': [
    {
      'title': 'RozdziaÅ‚ 1 - Wprowadzenie',
      'page': 15,
      'level': 1,
      'type': 'chapter'
    },
    {
      'title': '1.1 Podstawowe pojÄ™cia',
      'page': 17,
      'level': 2,
      'type': 'section'
    }
  ],
  'toc_entries_count': 15
}
```

**Lista zwracana:**
```python
processed_tocs = [
  { ... TOC 1 ... },
  { ... TOC 2 ... },
]
```

**Logi koÅ„cowe:**
```
ğŸ¯ Processed 2/3 TOCs
```

---

## PrzykÅ‚adowy Flow - End-to-End

### Scenariusz: PDF z 2 sekcjami TOC

**Input:**
```bash
python run_toc_pipeline.py documents/book.pdf
```

**Konsola Output:**
```
ğŸš€ Starting TOC pipeline for: book.pdf

ğŸ” Categorizing 5 candidates...
   Candidate 0: page 2, entries=15, total=18, ratio=0.83, proximity=True
     â†’ CERTAIN
   Candidate 1: page 5, entries=12, total=15, ratio=0.80, proximity=True
     â†’ CERTAIN
   Candidate 2: page 15, entries=3, total=20, ratio=0.15, proximity=True
     â†’ UNCERTAIN
   Candidate 3: page 50, entries=2, total=10, ratio=0.20, proximity=False
     â†’ REJECTED: bad_proximity
   Candidate 4: page 100, entries=1, total=5, ratio=0.20, proximity=False
     â†’ REJECTED: too_far

ğŸ” Found 2 certain TOCs
ğŸ” Found 1 uncertain TOCs
ğŸ” Rejected 2 false positives

ğŸ¤– Starting LLM processing for 3 TOC candidates...

ğŸ“„ Saved verification PDF: toc_verification_toc_2_150.pdf
ğŸ“‹ Entry filtering: 15 valid, 0 discarded (NULL level)
ğŸ“‹ PDFLLMProcessor extracted 15 valid entries
   âœ… Processed TOC at page 2

ğŸ“„ Saved verification PDF: toc_verification_toc_5_200.pdf
ğŸ“‹ Entry filtering: 12 valid, 1 discarded (NULL level)
ğŸ“‹ PDFLLMProcessor extracted 12 valid entries
   âœ… Processed TOC at page 5

ğŸ“„ Saved verification PDF: toc_verification_toc_15_300.pdf
âš ï¸ Discarding entry 'Random Text' - no level detected
âš ï¸ Discarding entry 'Another Text' - no level detected
âš ï¸ Discarding entry 'More Text' - no level detected
âš ï¸ No valid entries after filtering
   âŒ Rejected TOC at page 15

ğŸ¯ Processed 2/3 TOCs

ğŸ”— Merging 2 TOC sections...
   TOC at page 2: 15 entries
   TOC at page 5: 12 entries
ğŸ“‹ Merged result: 25 unique entries
   Coverage: pages 2-5

ğŸ¯ Selected best TOC: page 2-5

ğŸ”„ TOCFallbackLLMStrategy: passing through llm_processing_merged result

âœ… TOC orchestration complete: 25 entries found
   Method: llm_processing_merged
   Coverage: pages 2-5

âœ… Pipeline completed successfully
```

**Output JSON:**
```json
{
  "task_name": "TOCOrchestrator",
  "input_file": "documents/book.pdf",
  "toc_found": true,
  "detection_method": "llm_processing_merged",
  "coordinates": {
    "start_page": 2,
    "end_page": 5,
    "start_y": 150.5,
    "end_y": 780.2
  },
  "toc_entries": [
    {
      "title": "RozdziaÅ‚ 1 - Wprowadzenie",
      "page": 15,
      "level": 1,
      "type": "chapter"
    },
    {
      "title": "1.1 Podstawowe pojÄ™cia",
      "page": 17,
      "level": 2,
      "type": "section"
    }
    // ... 23 more entries
  ],
  "toc_entries_count": 25,
  "ready_for_splitting": true,
  "processing_stats": {
    "certain_count": 2,
    "uncertain_count": 1,
    "processed_count": 2,
    "rejected_count": 2
  }
}
```

**Debug Files Created:**
```
output/book/debug/
  â”œâ”€â”€ toc_verification_toc_2_150.pdf
  â”œâ”€â”€ toc_verification_toc_5_200.pdf
  â”œâ”€â”€ toc_verification_toc_15_300.pdf
  â””â”€â”€ detection_summary.json
```

---

## Spodziewane Efekty

### Sukces (TOC znaleziony)
- âœ… JSON z `toc_found: true`
- âœ… Lista entries z title, page, level, type
- âœ… WspÃ³Å‚rzÄ™dne PDF (do pÃ³Åºniejszego croppingu)
- âœ… Statystyki procesowania
- âœ… Debug PDFs w `output/{doc}/debug/`

### CzÄ™Å›ciowy sukces
- âš ï¸ TOC znaleziony ale niektÃ³re entries odrzucone (brak level)
- âš ï¸ Wielosekcyjny TOC zmergowany (moÅ¼e zawieraÄ‡ duplikaty)

### Niepowodzenie
- âŒ Brak TOC pattern match
- âŒ Za duÅ¼o kandydatÃ³w (> 25)
- âŒ Za duÅ¼o odrzuceÅ„ LLM (>= 4)
- âŒ Za duÅ¼o bÅ‚Ä™dÃ³w LLM (>= 3)
- âŒ Wszystkie entries odrzucone (NULL level)

### BÅ‚Ä™dy krytyczne
- ğŸ’¥ Brak dostÄ™pu do API LLM
- ğŸ’¥ Przekroczony rate limit
- ğŸ’¥ NiewaÅ¼ny JSON z LLM
- ğŸ’¥ Brak pliku PDF

---

## Konfiguracja (config.yaml)

### Parametry heurystyczne
```yaml
max_pages_to_scan: 1000      # Max stron do skanowania
min_toc_entries: 3           # Min entries w TOC
toc_keywords: [...]          # SÅ‚owa kluczowe TOC start
```

### Parametry LLM
```yaml
model: "gpt-4.1"             # Model OpenAI
temperature: 1.0             # Temperatura (default)
reasoning_effort: "low"      # Poziom reasoning
target_width_px: 700         # SzerokoÅ›Ä‡ obrazu
jpg_quality: 65              # JakoÅ›Ä‡ JPEG
max_concurrent: 1            # RÃ³wnolegÅ‚e requesty
rate_limit_backoff: 30.0     # Backoff po rate limit
```

### Limity bezpieczeÅ„stwa
```yaml
max_candidates: 50           # Nie uÅ¼ywane (TODO)
max_rejected_count: 5        # Nie uÅ¼ywane (TODO)
```
*Uwaga: Faktyczne limity w kodzie: 25 kandydatÃ³w, 4 odrzucenia, 3 bÅ‚Ä™dy*

---

## Pliki Output

### Luigi Output (task results)
```
output/toc_processing/toc_orchestrator/{file_hash}/output.json
output/toc_processing/toc_fallback_llm_strategy/{file_hash}/output.json
output/toc_processing/toc_heuristic_detector/{file_hash}/output.json
```

### Debug Files
```
output/{document_name}/debug/
  â”œâ”€â”€ toc_verification_toc_{page}_{y}.pdf  # Cropped TOC dla LLM
  â””â”€â”€ detection_summary.json                # Podsumowanie detekcji
```

---

## PrzykÅ‚ady Real-World

### Przypadek 1: Prosty TOC (1 sekcja)
```
Input: technical_book.pdf
Pattern match: "Table of Contents" na stronie 3
Heurystyka: 20 entries, toc_ratio=0.95 â†’ CERTAIN
LLM: 20/20 entries valid
Output: toc_found=true, 20 entries, pages 3-4
```

### Przypadek 2: Multi-section TOC
```
Input: large_manual.pdf
Pattern matches:
  - "Contents" na stronie 2 (15 entries)
  - "Contents (continued)" na stronie 5 (12 entries)
Heurystyka: Oba CERTAIN
LLM: 15/15 + 12/13 valid (1 odrzucony)
Merge: 27 unique entries
Output: toc_found=true, 27 entries, pages 2-5
```

### Przypadek 3: False Positives
```
Input: mixed_document.pdf
Pattern matches: 5 kandydatÃ³w
Kategoryzacja:
  - 1 CERTAIN (strona 3)
  - 2 UNCERTAIN (strony 15, 50)
  - 2 REJECTED (strony 100, 200)
LLM processing:
  - Strona 3: âœ… 18 entries
  - Strona 15: âŒ wszystkie NULL level
  - Strona 50: âŒ odrzucony (4 rejections)
Output: toc_found=true, 18 entries, page 3
```

### Przypadek 4: Brak TOC
```
Input: article.pdf
Pattern match: Brak
Output: toc_found=false, reason="no_pattern_match"
```

### Przypadek 5: Za duÅ¼o kandydatÃ³w
```
Input: messy_scanned.pdf
Pattern matches: 50 kandydatÃ³w (skanowane "Contents" wszÄ™dzie)
Kategoryzacja: 30 CERTAIN, 20 UNCERTAIN
LLM: ABORTED (> 25 kandydatÃ³w)
Output: toc_found=false, reason="too_many_candidates"
```

---

## Podsumowanie

Pipeline `luigi_toc_pipeline` to solidny, dwuetapowy system detekcji TOC:

1. **Stage 1 (Heuristic):** Szybka, wzorcowa detekcja + kategoryzacja
2. **Stage 2 (LLM):** Precyzyjna ekstrakcja strukturalna z GPT-4.1

**Mocne strony:**
- âœ… Hybrydowe podejÅ›cie (speed + accuracy)
- âœ… Multi-section TOC merging
- âœ… Solidne circuit breakers (zabezpieczenia)
- âœ… Debug visibility (PDFs + logs)

**Ograniczenia:**
- âš ï¸ Brak built-in TOC extraction (TODO w TOCFallbackLLMStrategy)
- âš ï¸ Proximity validation wyÅ‚Ä…czona (zawsze True)
- âš ï¸ Rate limiting moÅ¼e byÄ‡ agresywne (30s backoff)

**Use case:**
Idealny do automatycznej ekstrakcji TOC z PDF przed document splitting/chunking.
